{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XTvN0f-N4UJ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rWMvgLM6TMF",
        "outputId": "1cc67306-2584-45d4-a1e2-a3b75653312e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CplPjGF07NOR",
        "outputId": "8cd0db55-f538-46eb-f27b-9e655edd5e32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8 * len(words))\n",
        "n2 = int(0.9 * len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "id": "VKHNCOQK7UbE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "26aaWRooSnHk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP revisited\n",
        "n_embd = 10\n",
        "n_hidden = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((vocab_size, n_embd), generator=g)\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5 / 3) / ((n_embd * block_size) ** 0.5)\n",
        "b1 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1 # using b1 just for fun, it's useless because of batch normalization\n",
        "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
        "\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "# bnmean_running = torch.zeros((1, n_hidden))\n",
        "# bnstd_running = torch.ones((1, n_hidden))\n",
        "\n",
        "# Note: Many of these para,eters are being initialized in non-standard ways\n",
        "# because sometimes initializing with e.g. all zeros could mask an incorrect implementation\n",
        "# of the backward pass\n",
        "\n",
        "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "zsfKwNlu84XC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1978207-9f31-4225-ac64-7b393182668f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1\n",
        "  bnmeani = hpreact.mean(0, keepdim=1)\n",
        "  bnstdi = hpreact.std(0, keepdim=1)\n",
        "  hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
        "  with torch.no_grad():\n",
        "    bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
        "    bnstd_running = 0.999 * bnstd_running + 0.001 * bnstd\n",
        "    h = torch.tanh(hpreact)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    lr = 0.1 if i < 100000 else 0.01\n",
        "    for p in parameters:\n",
        "      p.data += -lr * p.grad\n",
        "\n",
        "    if i % 10000 == 0:\n",
        "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "Ezd5Fx6TF5h7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ompa4hrwG9SC",
        "outputId": "fd34344a-c770-4bf1-f350-88f3ac890d86"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0, 25],\n",
              "        [ 0, 25, 21],\n",
              "        ...,\n",
              "        [15, 12,  4],\n",
              "        [12,  4,  1],\n",
              "        [ 4,  1, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xtr[:20]]\n",
        "# print(emb.shape)\n",
        "# print(emb.view(emb.shape[0], -1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbBsqY5rGz83",
        "outputId": "5eecf480-a922-4c03-cd7b-ddc1b008e487"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3, 10])\n",
            "torch.Size([20, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHzkCU0DGKfa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}